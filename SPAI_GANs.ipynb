{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SPAI_GANs.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeqjBWBK8nZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image \n",
        "import glob, random \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPjzM6EW-YnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! unzip SPAI_lens_dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt2Fe9ZH-bJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smpl_img = Image.open(\"SPAI_lens_dataset/train/A/33.png\")\n",
        "plt.imshow(smpl_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVT77XDT-c7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RR = transforms.RandomRotation((0, 360))\n",
        "\n",
        "TT = transforms.ToTensor()\n",
        "TPIL = transforms.ToPILImage()\n",
        "myTransforms = transforms.Compose([RR, TT])\n",
        "\n",
        "img_R = myTransforms(smpl_img)\n",
        "plt.imshow(TPIL(img_R))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OoZaYaq-eiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, root, transforms=None):\n",
        "    self.transforms = transforms\n",
        "    path_A = root +'A'\n",
        "    self.files_A = glob.glob(path_A + '/*.*')\n",
        "    path_B = root +'B'\n",
        "    self.files_B = glob.glob(path_B + '/*.*')\n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    rand_A_file = self.files_A[random.randint(0, len(self.files_A)-1)] #Select random lens image file\n",
        "    rand_A_im = Image.open(rand_A_file) #Open random lens image file\n",
        "    tr_A = self.transforms(rand_A_im) #Transform random lens image\n",
        "    \n",
        "    rand_B_file = self.files_B[random.randint(0, len(self.files_B)-1)]\n",
        "    rand_B_im = Image.open(rand_B_file)\n",
        "    tr_B = self.transforms(rand_B_im)                           \n",
        "\n",
        "    return {'A':tr_A, 'B':tr_B, 'A_label':1.0, 'B_label':0.0}\n",
        "  \n",
        "  def __len__(self):\n",
        "    return 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jlRPAPg-gL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare the data\n",
        "\n",
        "data_path = 'SPAI_lens_dataset/'\n",
        "train_dataloader = torch.utils.data.DataLoader(ImageDataset(data_path+'train/',\n",
        "                                                           transforms=myTransforms),\n",
        "                                              batch_size=32,\n",
        "                                              shuffle=True)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(ImageDataset(data_path+'test/',\n",
        "                                                           transforms=myTransforms),\n",
        "                                              batch_size=32,\n",
        "                                              shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rbqwrHg-hsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Number of Batches:', len(train_dataloader))\n",
        "\n",
        "smpl_batch = next(iter(train_dataloader))\n",
        "\n",
        "print('A Data shape: ', smpl_batch['A'].shape)\n",
        "print(smpl_batch['A_label'])\n",
        "print('B Data shape: ', smpl_batch['B'].shape)\n",
        "print(smpl_batch['B_label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp6rFGIn-kHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(torch.nn.Module):\n",
        "  def __init__(self, nc, nfm):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.disc = nn.Sequential(# input: nc x 64 x 64,\n",
        "                            nn.Conv2d(nc, nfm, 4, 2, 1),\n",
        "                            # After 1st layer: nfm x 32 x 32)\n",
        "                            nn.BatchNorm2d(nfm),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Conv2d(nfm, nfm*2, 4, 2, 1),\n",
        "                            # After 2nd layer: nfm*2 x 16 x 16)\n",
        "                            nn.BatchNorm2d(nfm*2),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Conv2d(nfm*2, nfm*4, 4, 2, 1),\n",
        "                            # After 3rd layer: nfm*4 x 8 x 8)\n",
        "                            nn.BatchNorm2d(nfm*4),\n",
        "                            nn.ReLU(),    \n",
        "                            nn.Conv2d(nfm*4, nfm*8, 4, 2, 1),\n",
        "                            # After 4th layer: nfm*8 x 4 x 4)\n",
        "                            nn.BatchNorm2d(nfm*8),\n",
        "                            nn.ReLU(), \n",
        "                            nn.Conv2d(nfm*8, 1, 4, 1, 0),\n",
        "                            # After 5th layer: 1 x 1 x 1)\n",
        "                            nn.Sigmoid()\n",
        "                            )\n",
        "  def forward(self, inputs):\n",
        "    return self.disc(inputs)\n",
        "  \n",
        "class Generator(torch.nn.Module):\n",
        "  def __init__(self, nc, nfm, nz):\n",
        "    super(Generator, self).__init__()\n",
        "    self.gen = nn.Sequential(# input: nc x 64 x 64,\n",
        "                            nn.ConvTranspose2d(nz, nfm*8, 4, 1, 0),\n",
        "                            # After 1st layer: nfm x 32 x 32)\n",
        "                            nn.BatchNorm2d(nfm*8),\n",
        "                            nn.ReLU(),\n",
        "                            nn.ConvTranspose2d(nfm*8, nfm*4, 4, 2, 1),\n",
        "                            # After 2nd layer: nfm*2 x 16 x 16)\n",
        "                            nn.BatchNorm2d(nfm*4),\n",
        "                            nn.ReLU(),\n",
        "                            nn.ConvTranspose2d(nfm*4, nfm*2, 4, 2, 1),\n",
        "                            # After 3rd layer: nfm*4 x 8 x 8)\n",
        "                            nn.BatchNorm2d(nfm*2),\n",
        "                            nn.ReLU(),    \n",
        "                            nn.ConvTranspose2d(nfm*2, nfm, 4, 2, 1),\n",
        "                            # After 4th layer: nfm*8 x 4 x 4)\n",
        "                            nn.BatchNorm2d(nfm),\n",
        "                            nn.ReLU(), \n",
        "                            nn.ConvTranspose2d(nfm, nc, 4, 2, 1),\n",
        "                            # After 5th layer: 1 x 1 x 1)\n",
        "                            nn.Tanh()\n",
        "                            )\n",
        "  def forward(self, inputs):\n",
        "    return self.gen(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}